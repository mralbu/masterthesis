<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Hierarchical Multi-Task Linear Regression | Prediction of Petrophysical Properties Using Machine Learning and Hierarchical Multi-Task Linear Models</title>
  <meta name="description" content="Chapter 4 Hierarchical Multi-Task Linear Regression | Prediction of Petrophysical Properties Using Machine Learning and Hierarchical Multi-Task Linear Models" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Hierarchical Multi-Task Linear Regression | Prediction of Petrophysical Properties Using Machine Learning and Hierarchical Multi-Task Linear Models" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Hierarchical Multi-Task Linear Regression | Prediction of Petrophysical Properties Using Machine Learning and Hierarchical Multi-Task Linear Models" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="3-kabs-regression.html"/>
<link rel="next" href="conclusion.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="2-petrophysical-properties.html"><a href="2-petrophysical-properties.html"><i class="fa fa-check"></i><b>2</b> Measuring Petrophysical Properties</a><ul>
<li class="chapter" data-level="2.1" data-path="2-petrophysical-properties.html"><a href="2-petrophysical-properties.html#routine-core-analysis"><i class="fa fa-check"></i><b>2.1</b> Routine Core Analysis</a></li>
<li class="chapter" data-level="2.2" data-path="2-petrophysical-properties.html"><a href="2-petrophysical-properties.html#special-core-analysis"><i class="fa fa-check"></i><b>2.2</b> Special Core Analysis</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-petrophysical-properties.html"><a href="2-petrophysical-properties.html#mercury-injection-capillary-pressure"><i class="fa fa-check"></i><b>2.2.1</b> Mercury Injection Capillary Pressure</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-petrophysical-properties.html"><a href="2-petrophysical-properties.html#centrifuge-capillary-pressure"><i class="fa fa-check"></i><b>2.2.2</b> Centrifuge Capillary Pressure</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-petrophysical-properties.html"><a href="2-petrophysical-properties.html#relative-permeability"><i class="fa fa-check"></i><b>2.2.3</b> Relative Permeability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html"><i class="fa fa-check"></i><b>3</b> Absolute Permeability Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#pchg-feat-eng"><i class="fa fa-check"></i><b>3.1</b> Mercury Porosimetry Feature Engineering</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#statistical-features"><i class="fa fa-check"></i><b>3.1.1</b> Statistical Features</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#linear-features"><i class="fa fa-check"></i><b>3.1.2</b> Linear Features</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#pore-throat-size-class-distribution"><i class="fa fa-check"></i><b>3.1.3</b> Pore Throat Size Class Distribution</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#gauss-mixture-fit-feat"><i class="fa fa-check"></i><b>3.1.4</b> Gaussian Mixture Fit Features</a></li>
<li class="chapter" data-level="3.1.5" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#dimensionality-reduction-features"><i class="fa fa-check"></i><b>3.1.5</b> Dimensionality Reduction Features</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#absolute-permeability-regression-models"><i class="fa fa-check"></i><b>3.2</b> Absolute Permeability Regression Models</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#linear-regression-models"><i class="fa fa-check"></i><b>3.2.1</b> Linear Regression Models</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-kabs-regression.html"><a href="3-kabs-regression.html#non-linear-regression"><i class="fa fa-check"></i><b>3.2.2</b> Black-Box Machine Learning Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-hierarchical-linear-regression.html"><a href="4-hierarchical-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Hierarchical Multi-Task Linear Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="4-hierarchical-linear-regression.html"><a href="4-hierarchical-linear-regression.html#multi-task-linear-regression"><i class="fa fa-check"></i><b>4.1</b> Multi-Task Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="4-hierarchical-linear-regression.html"><a href="4-hierarchical-linear-regression.html#hierarchical-linear-regression-1"><i class="fa fa-check"></i><b>4.2</b> Hierarchical Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i>Conclusion</a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Prediction of Petrophysical Properties Using Machine Learning and Hierarchical Multi-Task Linear Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hierarchical-linear-regression" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Hierarchical Multi-Task Linear Regression</h1>
<p>Linear regression methods are widely used in petrophysical characterization. Compared to non-linear machine learning models, they have as advantages simplicity, interpretability and their inherent linear behavior on extrapolated predictions. For the estimation of special core analysis properties, which are costly to acquire and thus usually scarce, simple models with a low number of parameters and that can deliver interpretable probabilistic inferences are highly desirable. In this work, two different linear regression techniques are evaluated on special core analysis datasets.</p>
<p>On a dataset containing 135 capillary pressure curves estimated from centrifuge experiments, a multi-task linear regression model is fit and evaluated, and some of its properties are analyzed.</p>
<p>On another dataset, containing 226 unsteady-state water-oil relative permeability curves, partially pooled hierarchical linear regression models are evaluated and compared to simple linear regression models.</p>
<div id="multi-task-linear-regression" class="section level2">
<h2><span class="header-section-number">4.1</span> Multi-Task Linear Regression</h2>
<p>Using the parameterization <a href="4-hierarchical-linear-regression.html#eq:albu2">(4.1)</a>, proposed by <span class="citation">(Albuquerque et al. <a href="#ref-Albuquerque2018" role="doc-biblioref">2018</a>)</span>, a dataset containing parameters <span class="math inline">\(S_{wi}\)</span>, <span class="math inline">\(P_e\)</span>, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> fitted to each of the available 135 centrifuge capillary pressure curves, was assembled.</p>
<p><span class="math display" id="eq:albu2">\[\begin{equation} 
  S_w(P_c, S_{wi}, P_e, \alpha, \beta) = \frac{1+\alpha S_{wi}(P_c - P_e)^\beta}{(1+\alpha (P_c - P_e)^\beta}
  \tag{4.1}
\end{equation}\]</span></p>
<p>To each of these samples, features extracted from MICP curves obtained on corresponding rock fragments were associated in a dataset containing {<span class="math inline">\(S_{wi}\)</span>, <span class="math inline">\(P_e\)</span>, <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, <span class="math inline">\(k_{abs}\)</span>, <span class="math inline">\(r_{35}\)</span>, <span class="math inline">\(iqr\)</span>} values for each MICP and centrifuge capillary pressure curve pair. Significant correlations between corresponding centrifuge capillary pressure curves <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(S_{wi}\)</span> and MICP median pore throat radius <span class="math inline">\(r_{median}\)</span> parameters can be visualized in Figure <a href="4-hierarchical-linear-regression.html#fig:pcc-correlations2">4.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:pcc-dataset2"></span>
<img src="figure/2-9-pcc-dataset.png" alt="Sample of the experimental capillary pressure curve dataset (points) and fitted capillary pressure model (lines)." width="70%" />
<p class="caption">
Figure 4.1: Sample of the experimental capillary pressure curve dataset (points) and fitted capillary pressure model (lines).
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pcc-correlations2"></span>
<img src="figure/2-12a-correlations-pchg.png" alt="Correlations between parameters alpha, Swi and median pore throat radius of correspondent rock fragment p(log r) distribution." width="45%" /><img src="figure/2-12b-correlations-pchg.png" alt="Correlations between parameters alpha, Swi and median pore throat radius of correspondent rock fragment p(log r) distribution." width="45%" />
<p class="caption">
Figure 4.2: Correlations between parameters alpha, Swi and median pore throat radius of correspondent rock fragment p(log r) distribution.
</p>
</div>

<p>Given <span class="math inline">\(x\)</span> a vector of input parameters {<span class="math inline">\(k_{abs}\)</span>, <span class="math inline">\(r_{35}\)</span>, <span class="math inline">\(iqr\)</span>} and y a vector of output parameters {<span class="math inline">\(S_{wi}\)</span>, <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, <span class="math inline">\(P_e\)</span>}, and considering a multivariate gaussian distribution described by equation <a href="4-hierarchical-linear-regression.html#eq:normal-eq">(4.2)</a>, the conditional distribution of the output parameters given known input parameters <span class="math inline">\(p(y|x)\)</span> may be described by equations <a href="4-hierarchical-linear-regression.html#eq:posterior-distribution">(4.3)</a><a href="4-hierarchical-linear-regression.html#eq:posterior-mean">(4.4)</a><a href="4-hierarchical-linear-regression.html#eq:posterior-covariance">(4.5)</a>. Estimating mean and covariance matrix statistics of the multivariate gaussian distribution <a href="4-hierarchical-linear-regression.html#eq:normal-eq">(4.2)</a> on the assembled dataset, using maximum likelihood methods <span class="citation">(DeGroot and Schervish <a href="#ref-DeGroot2012" role="doc-biblioref">2012</a>)</span>, inference and uncertainty evaluation may be performed on desired new input <span class="math inline">\(x\)</span> values.</p>
<p><span class="math display" id="eq:normal-eq">\[\begin{equation} 
  \begin{pmatrix}
  x \\
  y
  \end{pmatrix} \sim \mathcal{N}\left(\begin{pmatrix}
  \mu_x \\
  \mu_y
  \end{pmatrix},\begin{pmatrix}
  \Sigma_{xx} &amp; \Sigma_{xy} \\
  \Sigma_{yy} &amp; \Sigma_{xy}
  \end{pmatrix}\right)
  \tag{4.2}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:posterior-distribution">\[\begin{equation} 
  p(y|x) \sim \mathcal{N}(\mu_{y|x}, \Sigma_{y|x})
  \tag{4.3}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:posterior-mean">\[\begin{equation} 
  \mu_{y|x} = \mu_y + (\Sigma_{xx}^{-1}\Sigma_{yx})^t(x-\mu_x)
  \tag{4.4}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:posterior-covariance">\[\begin{equation} 
  \Sigma_{y|x} = \Sigma_{yy} - \Sigma_{xy}^{t}\Sigma_{xx}^{-1}\Sigma_{yx}
  \tag{4.5}
\end{equation}\]</span></p>
<p>Given new <span class="math inline">\(x=\{k_{abs}, r_{35}, iqr\}\)</span> values, the expected capillary pressure curve parameters <span class="math inline">\(E[y|x]\)</span> may be obtained by the conditional mean <span class="math inline">\(\mu_{y|x}\)</span>. Uncertainty evaluation of this prediction may be executed using samples of the conditional distribution <span class="math inline">\(p(y|x)\)</span>. Figure <a href="4-hierarchical-linear-regression.html#fig:pcc-posterior-sample">4.3</a> displays examples of experimental capillary pressure curves and predictions of these curves using as input associated <span class="math inline">\(\{k_{abs}, r_{35}, iqr\}\)</span> values. Samples from the conditional distribution <span class="math inline">\(p(y|x)\)</span> are shown as grey lines and illustrate prediction uncertainty.</p>
<div class="figure" style="text-align: center"><span id="fig:pcc-posterior-sample"></span>
<img src="figure/4-3-pcc-posterior-sample.png" alt="Visual comparison of experimental capillary pressure curves (blue lines), samples from the conditional distribution (grey lines) and average predicted curves (dashed black lines)." width="90%" />
<p class="caption">
Figure 4.3: Visual comparison of experimental capillary pressure curves (blue lines), samples from the conditional distribution (grey lines) and average predicted curves (dashed black lines).
</p>
</div>

<p>On Figure <a href="4-hierarchical-linear-regression.html#fig:pcc-posterior-correlations">4.4</a>, a comparison between experimental and predicted capillary pressure curve parameters is shown. Due to inherent noise associated with heterogeneous reservoir rocks and, as also observed in Figure <a href="4-hierarchical-linear-regression.html#fig:pcc-posterior-sample">4.3</a>, there is significant dispersion of experimental and predicted parameters values. Both in Figures <a href="4-hierarchical-linear-regression.html#fig:pcc-posterior-correlations">4.4</a> and <a href="4-hierarchical-linear-regression.html#fig:pcc-posterior-tendency">4.5</a>, it is possible to visualize that capillary curve parameter predictions follow linear tendencies with absolute permeability. This property of linear model predictions is desirable, as it follows the expected physical behavior of reservoir rocks.</p>
<div class="figure" style="text-align: center"><span id="fig:pcc-posterior-correlations"></span>
<img src="figure/4-4-pcc-correlation-a.png" alt="Experimental capillary pressure curve parameters (blue dots and line tendency) and predicted parameters estimated using the posterior mean (black dots)." width="45%" /><img src="figure/4-4-pcc-correlation-b.png" alt="Experimental capillary pressure curve parameters (blue dots and line tendency) and predicted parameters estimated using the posterior mean (black dots)." width="45%" /><img src="figure/4-4-pcc-correlation-c.png" alt="Experimental capillary pressure curve parameters (blue dots and line tendency) and predicted parameters estimated using the posterior mean (black dots)." width="45%" /><img src="figure/4-4-pcc-correlation-d.png" alt="Experimental capillary pressure curve parameters (blue dots and line tendency) and predicted parameters estimated using the posterior mean (black dots)." width="45%" />
<p class="caption">
Figure 4.4: Experimental capillary pressure curve parameters (blue dots and line tendency) and predicted parameters estimated using the posterior mean (black dots).
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pcc-posterior-tendency"></span>
<img src="figure/4-5-pcc-posterior-tendency.png" alt="Behaviour of predicted capillary pressure curves with absolute permeability." width="70%" />
<p class="caption">
Figure 4.5: Behaviour of predicted capillary pressure curves with absolute permeability.
</p>
</div>
</div>
<div id="hierarchical-linear-regression-1" class="section level2">
<h2><span class="header-section-number">4.2</span> Hierarchical Linear Regression</h2>
<p>In a reservoir model, the prediction of petrophysical properties on simulation cells distant from wells with available sampled cores is commonly performed using linear regression methods <span class="citation">(Peters <a href="#ref-Peters2012" role="doc-biblioref">2012</a>)</span>. To account for sampling bias, special core analysis properties such as relative permeability and capillary pressure are commonly scaled according to reservoir wide available information, such as absolute permeability, porosity and geological facies models. For relative permeability, this procedure is commonly performed using simple linear regression <span class="citation">(Gelman et al. <a href="#ref-Gelman2014" role="doc-biblioref">2014</a>)</span> of relative permeability parameters as a function of absolute permeability.</p>
<p>On this work, simple linear and hierarchical linear regression models were evaluated in a dataset containing 226 unsteady-state water-oil relative permeability curves from several Brazilian reservoirs. Parameters for each of the 226 curves were fitted using maximum likelihood estimation <span class="citation">(Migon, Gamerman, and Louzada <a href="#ref-Migon2015" role="doc-biblioref">2015</a>)</span> and the LET parameterization <a href="4-hierarchical-linear-regression.html#eq:swd2">(4.6)</a><a href="4-hierarchical-linear-regression.html#eq:kro-let2">(4.7)</a><a href="4-hierarchical-linear-regression.html#eq:krw-let2">(4.8)</a> proposed in <span class="citation">(Lomeland, Ebeltoft, and Thomas <a href="#ref-Lomeland2005" role="doc-biblioref">2005</a>)</span>.</p>
<p><span class="math display" id="eq:swd2">\[\begin{equation} 
  S_{wD} = \frac{S_w - S_{wi}}{1 - S_{wi} - S_{or}} 
  \tag{4.6}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:kro-let2">\[\begin{equation} 
  k_{ro}(S_w) = k_{ro@S_{wi}}\frac{(1-S_{wD})^{L_o}}{(1-S_{wD})^{L_o} + E_o(S_{wD})^{T_o}}
  \tag{4.7}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:krw-let2">\[\begin{equation} 
  k_{rw}(S_w) = k_{rw@S_{or}}\frac{(S_{wD})^{L_w}}{(S_{wD})^{L_w} + E_w(1-S_{wD})^{T_w}}
  \tag{4.8}
\end{equation}\]</span></p>
<p>Categorical variables, such as field, reservoir or geological facies, may be used to group petrophysical models. A model that does not distinguish between groups, using constant intercept and slope parameters for all categories according to equation <a href="4-hierarchical-linear-regression.html#eq:simple-linear">(4.9)</a>, may be referred to as a non-pooled model <span class="citation">(Gelman et al. <a href="#ref-Gelman2014" role="doc-biblioref">2014</a>)</span>. Figure <a href="4-hierarchical-linear-regression.html#fig:non-pooled">4.6</a> displays a simple linear non-pooled regression model of irreducible water saturation <span class="math inline">\(S_{wi}\)</span> as the predicted <span class="math inline">\(y\)</span> variable and the logarithm of absolute permeability <span class="math inline">\(\log{k_{abs}}\)</span> as the observed <span class="math inline">\(x\)</span> variable. On equation <a href="4-hierarchical-linear-regression.html#eq:simple-linear">(4.9)</a>, <span class="math inline">\(n\)</span> represents the total number of data samples, indexed by the letter <span class="math inline">\(i\)</span>, and <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma_y^2\)</span> represent the intercept, slope and variance linear model parameters.</p>
<p><span class="math display" id="eq:simple-linear">\[\begin{equation} 
  y_i \sim \mathcal{N}(\alpha + \beta x, \sigma_y^2),\quad \text{for}\; i=1,...,n
  \tag{4.9}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:non-pooled"></span>
<img src="figure/4-6-simple-regression.png" alt="Non-pooled simple linear regression." width="90%" />
<p class="caption">
Figure 4.6: Non-pooled simple linear regression.
</p>
</div>
<p>Usually, though, separate linear regression models are fitted to each category of interest, in models that may be referred to as completely pooled. For each category <span class="math inline">\(j\)</span>, independent <span class="math inline">\(\alpha_j\)</span>, <span class="math inline">\(\beta_j\)</span> and <span class="math inline">\(\sigma_{y^j}^2\)</span> parameters are estimated, as described in equation <a href="4-hierarchical-linear-regression.html#eq:simple-linear-full">(4.10)</a>.</p>
<p><span class="math display" id="eq:simple-linear-full">\[\begin{equation} 
  y_i^j \sim \mathcal{N}(\alpha_j + \beta_j x_i^j, \sigma_{y^j}^2),\quad \text{for}\; i=1,...,n; \quad \text{for} \; i=1,...,J
  \tag{4.10}
\end{equation}\]</span></p>
<p>Figure <a href="4-hierarchical-linear-regression.html#fig:completely-pooled">4.7</a> displays a simple linear completely pooled regression model of irreducible water saturation <span class="math inline">\(S_{wi}\)</span> and the logarithm of absolute permeability <span class="math inline">\(\log{k_{abs}}\)</span>, grouped by reservoir. In completely pooled regression models, each linear regression model is independent of each other, with varying degrees of uncertainty on each model parameters <span class="math inline">\(\alpha_j\)</span>, <span class="math inline">\(\beta_j\)</span> and <span class="math inline">\(\sigma_{y^j}^2\)</span>. Categories with larger number of samples and smaller heterogeneities, usually display smaller uncertainties on model parameters.</p>
<div class="figure" style="text-align: center"><span id="fig:completely-pooled"></span>
<img src="figure/4-7-completely-pooled.png" alt="Completely pooled simple linear regression models, grouped by reservoir." width="90%" />
<p class="caption">
Figure 4.7: Completely pooled simple linear regression models, grouped by reservoir.
</p>
</div>

<p>Hierarchical or partially pooled linear regression models introduce information sharing and coupling between model parameters of different categories, modeling intercept and/or slope parameters as sampled from a latent parent distribution.</p>
<p>Varying intercept models, assume that the intercept of each category <span class="math inline">\(\alpha_j\)</span> is sampled from a common latent gaussian distribution <a href="4-hierarchical-linear-regression.html#eq:varying-intercepts-b">(4.12)</a>. This information sharing, has a regularizing effect of shrinking the partially pooled parameters towards a common mean <span class="math inline">\(\mu_\alpha\)</span>.</p>
<p><span class="math display" id="eq:varying-intercepts-a">\[\begin{equation} 
  y_i^j \sim \mathcal{N}(\alpha_j + \beta_j x_i^j, \sigma_{y^j}^2),\quad \text{for}\; i=1,...,n; \quad \text{for} \; j=1,...,J
  \tag{4.11}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:varying-intercepts-b">\[\begin{equation} 
  \alpha_j \sim \mathcal{N}(\mu_\alpha, \sigma_\alpha^2), \quad \text{for} \; j=1,...,J
  \tag{4.12}
\end{equation}\]</span></p>
<p>Varying slope models, assume that the slope of each category <span class="math inline">\(\beta_j\)</span> is sampled from a common latent gaussian distribution <a href="4-hierarchical-linear-regression.html#eq:varying-slopes-b">(4.14)</a>, with the same regularizing effect of shrinking the partially pooled parameters towards a common mean <span class="math inline">\(\mu_\beta\)</span>.</p>
<p><span class="math display" id="eq:varying-slopes-a">\[\begin{equation} 
  y_i^j \sim \mathcal{N}(\alpha_j + \beta_j x_i^j, \sigma_{y^j}^2),\quad \text{for}\; i=1,...,n; \quad \text{for} \; j=1,...,J
  \tag{4.13}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:varying-slopes-b">\[\begin{equation} 
  \beta_j \sim \mathcal{N}(\mu_\beta, \sigma_\beta^2), \quad \text{for} \; j=1,...,J
  \tag{4.14}
\end{equation}\]</span></p>
<p>Varying intercept and slope models, assume that both the intercept and slope of each category <span class="math inline">\(\alpha_j\)</span> and <span class="math inline">\(\beta_j\)</span> are sampled from a common latent multivariate gaussian distribution <a href="4-hierarchical-linear-regression.html#eq:varying-intercepts-slopes-b">(4.16)</a>.</p>
<p><span class="math display" id="eq:varying-intercepts-slopes-a">\[\begin{equation} 
  y_i^j \sim \mathcal{N}(\alpha_j + \beta_j x_i^j, \sigma_{y^j}^2),\quad \text{for}\; i=1,...,n; \quad \text{for} \; j=1,...,J
  \tag{4.15}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:varying-intercepts-slopes-b">\[\begin{equation} 
  \begin{pmatrix}
  \alpha_j \\
  \beta_j
  \end{pmatrix} \sim \mathcal{N}\left(\begin{pmatrix}
  \mu_\alpha \\
  \mu_\beta
  \end{pmatrix},\begin{pmatrix}
  \sigma_\alpha^2 &amp; \rho \sigma_\alpha \sigma_\beta \\
  \rho \sigma_\alpha \sigma_\beta &amp; \sigma_\beta^2
  \end{pmatrix}\right),\quad \text \quad \text{for} \; j=1,...,J
  \tag{4.16}
\end{equation}\]</span></p>
<p>For the dataset of 226 unsteady-state water-oil relative permeability curve LET parameters, hierarchical varying slope models of relative permeability endpoint parameters <span class="math inline">\(S_{wi}\)</span>, <span class="math inline">\(S_{or}\)</span>, <span class="math inline">\(k_{ro}@S_{wi}\)</span> and <span class="math inline">\(k_{rw}@S_{or}\)</span>, and logarithm of absolute permeability <span class="math inline">\(\log{k_{abs}}\)</span> were fit and compared to completely pooled simple linear regression models, grouped by reservoir.</p>
<p>Both hierarchical and simple linear regression model parameters were inferred using bayesian Hamiltonian Markov-Chain Monte-Carlo <span class="citation">(Hoffman and Gelman <a href="#ref-Hoffman2014" role="doc-biblioref">2014</a>)</span> and the software Stan <span class="citation">(Carpenter et al. <a href="#ref-Carpenter2017" role="doc-biblioref">2017</a>)</span>. Default weakly informative model parameter priors were utilized, following the recommendations of <span class="citation">(Gelman et al. <a href="#ref-Gelman2008" role="doc-biblioref">2008</a>)</span>.</p>
<p>Comparison between hierarchical and simple linear regression models were performed using the root mean squared error RMSE, the Watanabe-Akaike Information Criteria (WAIC), the leave-one-out information criteria (LOOIC), and the bayesian R-squared <span class="math inline">\(R^2\)</span> and adjusted R-squared <span class="math inline">\(R_{adj}^2\)</span> metrics <span class="citation">(Gelman et al. <a href="#ref-GelmanGoodrich2019" role="doc-biblioref">2019</a>)</span><span class="citation">(Vehtari, Gelman, and Gabry <a href="#ref-Vehtari2017" role="doc-biblioref">2017</a>)</span>. The WAIC and LOOIC information criteria provide a trade-off between goodness-of-fit and model complexity, with lower WAIC and LOOIC values corresponding to lower cross-validation errors.</p>
<p>Hierarchical varying slope and simple linear regression models of irreducible water saturation <span class="math inline">\(S_{wi}\)</span> and logarithm of absolute permeability <span class="math inline">\(\log{k_{abs}}\)</span> were evaluated on the assembled dataset.</p>
<p>Table <a href="4-hierarchical-linear-regression.html#tab:swi-regression-metrics">4.1</a> displays the obtained regression metrics for each fitted model. Hierarchical linear regression achieved slightly better WAIC, LOOIC and <span class="math inline">\(R_{adj}^2\)</span> metrics.</p>
<table>
<caption><span id="tab:swi-regression-metrics">Table 4.1: </span> <span class="math inline">\(S_{wi}\)</span> linear regression model metrics.</caption>
<colgroup>
<col width="43%" />
<col width="10%" />
<col width="12%" />
<col width="11%" />
<col width="7%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Regression Model</th>
<th align="center">RMSE</th>
<th align="center">WAIC</th>
<th align="left">LOOIC</th>
<th><span class="math inline">\(R^2\)</span></th>
<th><span class="math inline">\(R_{adj}^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Simple Linear Regression</td>
<td align="center">0.05</td>
<td align="center">-681.48</td>
<td align="left">-680.96</td>
<td>0.20</td>
<td>0.16</td>
</tr>
<tr class="even">
<td align="center">Hierarchical Linear Regression</td>
<td align="center">0.05</td>
<td align="center">-684.89</td>
<td align="left">-684.66</td>
<td>0.24</td>
<td>0.17</td>
</tr>
</tbody>
</table>
<p>Figure <a href="4-hierarchical-linear-regression.html#fig:swi-simple-hierarchical">4.8</a> displays simple and hierarchical linear regression <span class="math inline">\(S_{wi}\)</span> vs <span class="math inline">\(\log{k_{abs}}\)</span> models, grouped by reservoir. Black dots represent observed samples, light blue lines represent samples from the posterior distribution of intercept and slope parameters, and dark blue lines represent mean intercept and slope parameters, for each reservoir.</p>
<p>Completely pooled, simple linear regression models display larger between-groups slope variations and uncertainty, as shown in Figure <a href="4-hierarchical-linear-regression.html#fig:swi-simple-hierarchical-coefs">4.9</a>. Reservoirs with large number of samples, such as reservoir F, display only small changes between hierarchical and simple linear regression model posterior distributions. A stronger regularizing effect is displayed in reservoir H, which contains a small number of samples. Overall behavior consistency of <span class="math inline">\(S_{wi}\)</span> with respect to <span class="math inline">\(\log{k_{abs}}\)</span> is increased in the hierarchical partially pooled linear model, as slopes are regressed towards a common mean. As information is shared between different reservoirs, posterior uncertainties are noticeably reduced in the hierarchical linear model.</p>
<div class="figure" style="text-align: center"><span id="fig:swi-simple-hierarchical"></span>
<img src="figure/4-8-swi-simple.png" alt="Simple (top) and Hierarchical (bottom) linear regression models of Swi vs log(kabs), grouped by reservoir." width="75%" /><img src="figure/4-8-swi-hierarchical.png" alt="Simple (top) and Hierarchical (bottom) linear regression models of Swi vs log(kabs), grouped by reservoir." width="75%" />
<p class="caption">
Figure 4.8: Simple (top) and Hierarchical (bottom) linear regression models of Swi vs log(kabs), grouped by reservoir.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:swi-simple-hierarchical-coefs"></span>
<img src="figure/4-9-swi-coefs-intercept.png" alt="Intercept (top) and slope (bottom), simple and hierarchical linear regression Swi vs log(kabs) model  parameters, grouped by reservoir." width="75%" /><img src="figure/4-9-swi-coefs-slopes.png" alt="Intercept (top) and slope (bottom), simple and hierarchical linear regression Swi vs log(kabs) model  parameters, grouped by reservoir." width="75%" />
<p class="caption">
Figure 4.9: Intercept (top) and slope (bottom), simple and hierarchical linear regression Swi vs log(kabs) model parameters, grouped by reservoir.
</p>
</div>

<p>Hierarchical varying slope and simple linear regression models of residual oil saturation <span class="math inline">\(S_{or}\)</span> and logarithm of absolute permeability <span class="math inline">\(\log{k_{abs}}\)</span> were evaluated on the assembled dataset.</p>
<p>Table <a href="4-hierarchical-linear-regression.html#tab:sor-regression-metrics">4.2</a> displays the obtained regression metrics for each fitted model. Both models achieved similar WAIC, LOOIC and <span class="math inline">\(R_{adj}^2\)</span> metrics.</p>
<table>
<caption><span id="tab:sor-regression-metrics">Table 4.2: </span> <span class="math inline">\(S_{or}\)</span> linear regression model metrics.</caption>
<colgroup>
<col width="43%" />
<col width="10%" />
<col width="12%" />
<col width="11%" />
<col width="7%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Regression Model</th>
<th align="center">RMSE</th>
<th align="center">WAIC</th>
<th align="left">LOOIC</th>
<th><span class="math inline">\(R^2\)</span></th>
<th><span class="math inline">\(R_{adj}^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Simple Linear Regression</td>
<td align="center">0.09</td>
<td align="center">-414.47</td>
<td align="left">-413.64</td>
<td>0.18</td>
<td>0.11</td>
</tr>
<tr class="even">
<td align="center">Hierarchical Linear Regression</td>
<td align="center">0.09</td>
<td align="center">-414.40</td>
<td align="left">-414.06</td>
<td>0.22</td>
<td>0.11</td>
</tr>
</tbody>
</table>
<p>Figure <a href="4-hierarchical-linear-regression.html#fig:sor-simple-hierarchical">4.10</a> displays simple and hierarchical linear regression <span class="math inline">\(S_{or}\)</span> vs <span class="math inline">\(\log{k_{abs}}\)</span> models, grouped by reservoir. Black dots represent observed samples, light blue lines represent samples from the posterior distribution of intercept and slope parameters, and dark blue lines represent mean intercept and slope parameters, for each reservoir.</p>
<p>Completely pooled, simple linear regression models display larger between-groups slope variations and uncertainty, as shown in Figure <a href="4-hierarchical-linear-regression.html#fig:sor-simple-hierarchical-coefs">4.11</a>. Reservoirs with large number of samples, such as reservoir F, show only small changes between hierarchical and simple linear regression model posterior distributions. A stronger regularizing effect is displayed in reservoir I, which contains a small number of samples. Overall behavior consistency of <span class="math inline">\(S_{or}\)</span> with respect to <span class="math inline">\(\log{k_{abs}}\)</span> is increased in the hierarchical partially pooled linear model, as slopes are regressed towards a common mean. As information is shared between different reservoirs, posterior uncertainties are noticeably reduced in the hierarchical linear model.</p>
<div class="figure" style="text-align: center"><span id="fig:sor-simple-hierarchical"></span>
<img src="figure/4-10-sor-simple.png" alt="Simple (top) and Hierarchical (bottom) linear regression models of Sor vs log(kabs), grouped by reservoir." width="75%" /><img src="figure/4-10-sor-hierarchical.png" alt="Simple (top) and Hierarchical (bottom) linear regression models of Sor vs log(kabs), grouped by reservoir." width="75%" />
<p class="caption">
Figure 4.10: Simple (top) and Hierarchical (bottom) linear regression models of Sor vs log(kabs), grouped by reservoir.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:sor-simple-hierarchical-coefs"></span>
<img src="figure/4-11-sor-intercept.png" alt="Intercept (top) and slope (bottom), simple and hierarchical linear regression Sor vs log(kabs) model  parameters, grouped by reservoir." width="75%" /><img src="figure/4-11-sor-slopes.png" alt="Intercept (top) and slope (bottom), simple and hierarchical linear regression Sor vs log(kabs) model  parameters, grouped by reservoir." width="75%" />
<p class="caption">
Figure 4.11: Intercept (top) and slope (bottom), simple and hierarchical linear regression Sor vs log(kabs) model parameters, grouped by reservoir.
</p>
</div>

<p>Hierarchical varying slope and simple linear regression models of oil relative permeability at irreducible water saturation condition <span class="math inline">\(k_{ro}@S_{wi}\)</span> and logarithm of absolute permeability <span class="math inline">\(\log{k_{abs}}\)</span> were evaluated on the assembled dataset.</p>
<p>Table <a href="4-hierarchical-linear-regression.html#tab:kro-regression-metrics">4.3</a> displays the obtained regression metrics for each fitted model. Hierarchical linear regression achieved slightly better WAIC, LOOIC and <span class="math inline">\(R_{adj}^2\)</span> metrics.</p>
<table>
<caption><span id="tab:kro-regression-metrics">Table 4.3: </span> <span class="math inline">\(k_{ro}@S_{wi}\)</span> linear regression model metrics.</caption>
<colgroup>
<col width="43%" />
<col width="10%" />
<col width="12%" />
<col width="11%" />
<col width="7%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Regression Model</th>
<th align="center">RMSE</th>
<th align="center">WAIC</th>
<th align="left">LOOIC</th>
<th><span class="math inline">\(R^2\)</span></th>
<th><span class="math inline">\(R_{adj}^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Simple Linear Regression</td>
<td align="center">0.20</td>
<td align="center">-48.72</td>
<td align="left">-47.50</td>
<td>0.34</td>
<td>0.28</td>
</tr>
<tr class="even">
<td align="center">Hierarchical Linear Regression</td>
<td align="center">0.20</td>
<td align="center">-62.02</td>
<td align="left">-61.77</td>
<td>0.39</td>
<td>0.33</td>
</tr>
</tbody>
</table>
<p>Figure <a href="4-hierarchical-linear-regression.html#fig:kro-simple-hierarchical">4.12</a> displays simple and hierarchical linear regression <span class="math inline">\(k_{ro}@S_{wi}\)</span> vs <span class="math inline">\(\log{k_{abs}}\)</span> models, grouped by reservoir. Black dots represent observed samples, light blue lines represent samples from the posterior distribution of intercept and slope parameters, and dark blue lines represent mean intercept and slope parameters, for each reservoir.</p>
<p>Completely pooled, simple linear regression models display larger between-groups slope variations and uncertainty, as shown in Figure <a href="4-hierarchical-linear-regression.html#fig:kro-simple-hierarchical-coefs">4.13</a>. Reservoirs with large number of samples, such as reservoir F, show only small changes between hierarchical and simple linear regression model posterior distributions. A stronger regularizing effect is displayed in reservoir D, which contains a small number of samples. Overall behavior consistency of <span class="math inline">\(k_{ro}@S_{wi}\)</span> in respect to <span class="math inline">\(\log{k_{abs}}\)</span> is increased in the hierarchical partially pooled linear model, as slopes are regressed towards a common mean. As information is shared between different reservoirs, posterior uncertainties are noticeably reduced in the hierarchical linear model.</p>
<div class="figure" style="text-align: center"><span id="fig:kro-simple-hierarchical"></span>
<img src="figure/4-12-kro-simple.png" alt="Simple (top) and Hierarchical (bottom) linear regression models of kro@Swi vs log(kabs), grouped by reservoir." width="75%" /><img src="figure/4-12-kro-hierarchical.png" alt="Simple (top) and Hierarchical (bottom) linear regression models of kro@Swi vs log(kabs), grouped by reservoir." width="75%" />
<p class="caption">
Figure 4.12: Simple (top) and Hierarchical (bottom) linear regression models of <a href="mailto:kro@Swi" class="email">kro@Swi</a> vs log(kabs), grouped by reservoir.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:kro-simple-hierarchical-coefs"></span>
<img src="figure/4-13-kro-intercept.png" alt="Intercept (top) and slope (bottom), simple and hierarchical linear regression kro@Swi vs log(kabs) model  parameters, grouped by reservoir." width="75%" /><img src="figure/4-13-kro-slopes.png" alt="Intercept (top) and slope (bottom), simple and hierarchical linear regression kro@Swi vs log(kabs) model  parameters, grouped by reservoir." width="75%" />
<p class="caption">
Figure 4.13: Intercept (top) and slope (bottom), simple and hierarchical linear regression <a href="mailto:kro@Swi" class="email">kro@Swi</a> vs log(kabs) model parameters, grouped by reservoir.
</p>
</div>

<p>Hierarchical varying slope and simple linear regression models of water relative permeability at residual oil saturation condition <span class="math inline">\(k_{rw}@S_{or}\)</span> and logarithm of absolute permeability <span class="math inline">\(\log{k_{abs}}\)</span> were evaluated on the assembled dataset.</p>
<p>Table <a href="4-hierarchical-linear-regression.html#tab:krw-regression-metrics">4.4</a> displays the obtained regression metrics for each fitted model. Hierarchical linear regression achieved slightly better WAIC, LOOIC and <span class="math inline">\(R_{adj}^2\)</span> metrics.</p>
<table>
<caption><span id="tab:krw-regression-metrics">Table 4.4: </span> <span class="math inline">\(k_{rw}@S_{or}\)</span> linear regression model metrics.</caption>
<colgroup>
<col width="43%" />
<col width="10%" />
<col width="12%" />
<col width="11%" />
<col width="7%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Regression Model</th>
<th align="center">RMSE</th>
<th align="center">WAIC</th>
<th align="left">LOOIC</th>
<th><span class="math inline">\(R^2\)</span></th>
<th><span class="math inline">\(R_{adj}^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Simple Linear Regression</td>
<td align="center">0.10</td>
<td align="center">-366.62</td>
<td align="left">-366.13</td>
<td>0.20</td>
<td>0.16</td>
</tr>
<tr class="even">
<td align="center">Hierarchical Linear Regression</td>
<td align="center">0.10</td>
<td align="center">-372.34</td>
<td align="left">-372.18</td>
<td>0.24</td>
<td>0.17</td>
</tr>
</tbody>
</table>
<p>Figure <a href="4-hierarchical-linear-regression.html#fig:krw-simple-hierarchical">4.14</a> displays simple and hierarchical linear regression <span class="math inline">\(k_{rw}@S_{or}\)</span> vs <span class="math inline">\(\log{k_{abs}}\)</span> models, grouped by reservoir. Black dots represent observed samples, light blue lines represent samples from the posterior distribution of intercept and slope parameters, and dark blue lines represent mean intercept and slope parameters, for each reservoir.</p>
<p>Completely pooled, simple linear regression models display larger between-groups slope variations and uncertainty, as shown in Figure <a href="4-hierarchical-linear-regression.html#fig:krw-simple-hierarchical-coefs">4.15</a>. Reservoirs with large number of samples, such as reservoir F, show only small changes between hierarchical and simple linear regression model posterior distributions. A stronger regularizing effect is displayed in reservoir D, which contains a small number of samples. Overall behavior consistency of <span class="math inline">\(k_{rw}@S_{or}\)</span> in respect to <span class="math inline">\(\log{k_{abs}}\)</span> is increased in the hierarchical partially pooled linear model, as slopes are regressed towards a common mean. As information is shared between different reservoirs, posterior uncertainties are noticeably reduced in the hierarchical linear model.</p>
<div class="figure" style="text-align: center"><span id="fig:krw-simple-hierarchical"></span>
<img src="figure/4-14-krw-simple.png" alt="Simple (top) and Hierarchical (bottom) linear regression models of krw@Sor vs log(kabs), grouped by reservoir." width="75%" /><img src="figure/4-14-krw-hierarchical.png" alt="Simple (top) and Hierarchical (bottom) linear regression models of krw@Sor vs log(kabs), grouped by reservoir." width="75%" />
<p class="caption">
Figure 4.14: Simple (top) and Hierarchical (bottom) linear regression models of <a href="mailto:krw@Sor" class="email">krw@Sor</a> vs log(kabs), grouped by reservoir.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:krw-simple-hierarchical-coefs"></span>
<img src="figure/4-15-krw-intercept.png" alt="Intercept (top) and slope (bottom), simple and hierarchical linear regression krw@Sor vs log(kabs) model  parameters, grouped by reservoir." width="75%" /><img src="figure/4-15-krw-slopes.png" alt="Intercept (top) and slope (bottom), simple and hierarchical linear regression krw@Sor vs log(kabs) model  parameters, grouped by reservoir." width="75%" />
<p class="caption">
Figure 4.15: Intercept (top) and slope (bottom), simple and hierarchical linear regression <a href="mailto:krw@Sor" class="email">krw@Sor</a> vs log(kabs) model parameters, grouped by reservoir.
</p>
</div>

<p>Posterior distribution of latent <span class="math inline">\(\mu_\alpha\)</span> and <span class="math inline">\(\mu_\beta\)</span> parameters of hierarchical linear regression models represent average behavior of model parameters across the different evaluated categories. Thus, they represent quantified petrophysical parameter model analogues, and may be used for preliminary characterization of reservoirs with similar characteristics as the ones used in the assembled model, but with no sampled data.</p>
<p>Multi-task simple and varying slopes hierarchical linear regression models, grouped by reservoir, were fitted to the assembled LET relative permeability parameter dataset. Comparison of WAIC and LOOIC metrics between them is shown in Table <a href="4-hierarchical-linear-regression.html#tab:multi-task-regression">4.5</a>, displaying slightly better results for the multi-task hierarchical linear regression model.</p>
<table style="width:74%;">
<caption><span id="tab:multi-task-regression">Table 4.5: </span> Multi-task linear regression model metrics.</caption>
<colgroup>
<col width="47%" />
<col width="12%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Regression Model</th>
<th align="center">WAIC</th>
<th align="center">LOOIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Simple Linear Regression</td>
<td align="center">1119.6</td>
<td align="center">1129.8</td>
</tr>
<tr class="even">
<td align="center">Hierarchical Linear Regression</td>
<td align="center">1043.3</td>
<td align="center">1048.0</td>
</tr>
</tbody>
</table>
<p>The posterior distribution of the LET relative permeability parameters for a given reservoir and logarithmic absolute permeability may be used to sample relative permeability curves, fully incorporating the information from the available dataset, as exemplified in Figure <a href="4-hierarchical-linear-regression.html#fig:multi-task">4.16</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:multi-task"></span>
<img src="figure/4-16-multi-task.png" alt="Example of multivariate posterior sample of relative permeability curves, fully incorporating the information from the available dataset." width="80%" />
<p class="caption">
Figure 4.16: Example of multivariate posterior sample of relative permeability curves, fully incorporating the information from the available dataset.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Albuquerque2018">
<p>Albuquerque, Marcelo R, Felipe M Eler, Heitor V R Camargo, André Compan, Dario Cruz, and Carlos Pedreira. 2018. “Estimation of Capillary Pressure Curves from Centrifuge Measurements using Inverse Methods.” <em>Rio Oil &amp; Gas Expo and Conference 2018,</em></p>
</div>
<div id="ref-Carpenter2017">
<p>Carpenter, Bob, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus A. Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. 2017. “Stan: A probabilistic programming language.” <em>Journal of Statistical Software</em> 76 (1). <a href="https://doi.org/10.18637/jss.v076.i01">https://doi.org/10.18637/jss.v076.i01</a>.</p>
</div>
<div id="ref-DeGroot2012">
<p>DeGroot, Morris H., and Mark J. Schervish. 2012. <em>Probability and Statistics</em>. Edited by Addison-Wesley.</p>
</div>
<div id="ref-Gelman2014">
<p>Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2014. <em>Bayesian Data Analysis</em>. 3. <a href="https://doi.org/10.1017/CBO9781107415324.004">https://doi.org/10.1017/CBO9781107415324.004</a>.</p>
</div>
<div id="ref-GelmanGoodrich2019">
<p>Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” <em>The American Statistician</em> 73 (3): 307–9.</p>
</div>
<div id="ref-Gelman2008">
<p>Gelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu Sung Su. 2008. “A weakly informative default prior distribution for logistic and other regression models.” <em>Annals of Applied Statistics</em> 2 (4): 1360–83. <a href="https://doi.org/10.1214/08-AOAS191">https://doi.org/10.1214/08-AOAS191</a>.</p>
</div>
<div id="ref-Hoffman2014">
<p>Hoffman, Matthew D., and Andrew Gelman. 2014. “The no-U-turn sampler: Adaptively setting path lengths in Hamiltonian Monte Carlo.” <em>Journal of Machine Learning Research</em> 15: 1593–1623. <a href="http://arxiv.org/abs/1111.4246">http://arxiv.org/abs/1111.4246</a>.</p>
</div>
<div id="ref-Lomeland2005">
<p>Lomeland, Frode, Einar Ebeltoft, and Wibeke Hammervold Thomas. 2005. “A new versatile relative permeability correlation.” <em>International Symposium of the Society of Core Analysts, Toronto, Canada</em>, 1–12.</p>
</div>
<div id="ref-Migon2015">
<p>Migon, Helio, Dani Gamerman, and Francisco Louzada. 2015. <em>Statistical Inference</em>. Second.</p>
</div>
<div id="ref-Peters2012">
<p>Peters, E. J. 2012. <em>Advanced Petrophysics</em>. Austin: Live Oak Book Company.</p>
</div>
<div id="ref-Vehtari2017">
<p>Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC.” <em>Statistics and Computing</em> 27 (5): 1413–32. <a href="https://doi.org/10.1007/s11222-016-9696-4">https://doi.org/10.1007/s11222-016-9696-4</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="3-kabs-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
